# ==== Libraries ====
using LinearAlgebra, Distributions, StatsBase, Random, PDMats

import Base: *
*(v::Any, Œ£::PDMats.PDiagMat{Float64,Array{Float64,1}}) = v*(Œ£*I(size(Œ£,1)))
*(v::Array{Float64,2}, Œ£::PDMats.PDiagMat{Float64,Array{Float64,1}}) = v*(Œ£*I(size(Œ£,1)))
*(v::Any, Œ£::PDMat{Float64,Array{Float64,2}}) = v*(Œ£*I(size(Œ£,1)))
*(v::Array{Float64,2}, Œ£::PDMat{Float64,Array{Float64,2}}) = v*(Œ£*I(size(Œ£,1)))

# ===================

# ==== Functions ====
function EKF(sys, y, u, t, x‚ÇÄ, Q, R)
# (X‚Çë,Œº,Œ£) = EKF(SYS,Y,U,T,X‚ÇÄ,Q,R)
#	Solves a state estimation problem using the Extended Kalman Filter (EKF).
#	Consider the stochastic nonlinear discrete-time state-space system
#			x‚Çñ‚Çä‚ÇÅ = f(x‚Çñ,u‚Çñ) + v‚Çñ,		v‚Çñ ~ ùìù(0,Q)
#			y‚Çñ   = g(x‚Çñ)    + z‚Çñ,		z‚Çñ ~ ùìù(0,R)
#	with prior distribution X‚ÇÄ ~ ùìù(Œº‚ÇÄ,Œ£‚ÇÄ).
#	The EKF approximates the filtering distribution x‚Çñ ~ p(x‚Çñ|y‚ÇÄ,‚ãØ,y‚Çñ) ‚âà ùìù(Œº‚Çñ,Œ£‚Çñ) by first
#	computing, for each time-step, a linearization of the functions f:‚Ñù‚Åø√ó‚Ñù·µñ‚Üí‚Ñù‚Åø and g:‚Ñù‚Åø‚Üí‚Ñù·µê,
#			x‚Çñ‚Çä‚ÇÅ = A‚Çñx + B‚Çñu + v‚Çñ
#			y‚Çñ   = C‚Çñx       + z‚Çñ
#	with A‚Çñ = ‚àÇf/‚àÇx|‚Çç‚Çì‚Çñ,·µ§‚Çñ‚Çé, B‚Çñ = ‚àÇf/‚àÇu|‚Çç‚Çì‚Çñ,·µ§‚Çñ‚Çé and C‚Çñ = ‚àÇg/‚àÇx|‚Çç‚Çì‚Çñ‚Çé.
#	The approximation is then computed using using a Bayesian approach:
#		1) Compute the predictive distribution
#			X‚Çö ~ p(x‚Çñ|y‚ÇÅ,‚ãØ,y‚Çñ‚Çã‚ÇÅ) ‚âà ùìù(Œº‚Åª‚Çñ,Œ£‚Åª‚Çñ) = ùìù(A‚Çñx‚Çñ‚Çã‚ÇÅ+B‚Çñu‚Çñ‚Çã‚ÇÅ, A‚Çñ*Œ£‚Çñ‚Çã‚ÇÅ*A‚Çñ·µÄ + Q)
#		2) Use Bayes' rule to compute the filtering distribution
#			X‚Çö ~ p(x‚Çñ|y‚ÇÅ,‚ãØ,y‚Çñ)   ‚âà ùìù(Œº‚Çñ,Œ£‚Çñ)   = ùìù(Œº‚Åª‚Çñ+K‚Çñ(y‚Çñ-C‚ÇñŒº‚Åª‚Çñ), Œ£‚Åª‚Çñ+K‚Çñ(C‚ÇñŒ£‚Åª‚ÇñC‚Çñ·µÄ+R)K‚Çñ·µÄ)
#		   with K‚Çñ = Œ£‚Åª‚Çñ C‚Çñ·µÄ(C‚Çñ·µÄŒ£‚Åª‚ÇñC‚Çñ·µÄ+R)‚Åª¬π, the optimal Kalman estimator.
#
	# Auxiliary variables
	(f,g,A,~,C,Œît,N‚Çì,N·µß,N·µ§) = sys
	t = t[1]:Œît:t[end]

	Œº = zeros(N‚Çì,   length(t))		# List of means 	(Œº = [Œº‚ÇÄ,‚ãØ,Œº‚Çú])
	Œ£ = zeros(N‚Çì,N‚Çì,length(t))		# List of variances (Œ£ = [Œ£‚ÇÄ,‚ãØ,Œ£‚Çú])

	# Auxiliary functions
	K(S‚Åª‚Çñ,C‚Çñ) = S‚Åª‚Çñ * C‚Çñ'*(C‚Çñ*S‚Åª‚Çñ*C‚Çñ' + R)^(-1) 	# Optimal Kalman Gain

	# == EKF FILTER ==
	# 1. UPDATING THE INITIAL STATE DISTRIBUTION
	C‚Çñ = C(x‚ÇÄ.Œº)					# Jacobian C‚Çñ = ‚àÇg/‚àÇx|‚Çç‚Çì‚Çñ‚Çé

	Œº‚Çñ =   x‚ÇÄ.Œº + K(x‚ÇÄ.Œ£,C‚Çñ)*(y[:,1] - C‚Çñ*x‚ÇÄ.Œº)
	Œ£‚Çñ = I*x‚ÇÄ.Œ£ - K(x‚ÇÄ.Œ£,C‚Çñ)*(C‚Çñ*x‚ÇÄ.Œ£*C‚Çñ' + R)*K(x‚ÇÄ.Œ£,C‚Çñ)'

	# Creates the stack of filtering distributions X·µ§ ~ p(x‚Çñ|y‚ÇÅ,‚ãØ,y‚Çñ)
	#  and saves the initial mean and covariance.
	X‚Çë = [MvNormal(Œº‚Çñ, Symmetric(Œ£‚Çñ))];	Œº[:,1] = Œº‚Çñ; Œ£[:,:,1] = Œ£‚Çñ

	for k ‚àà 1:length(t)-1
		# 2. PREDICTION STEP
		A‚Çñ = A(Œº‚Çñ, u[:,k]);		# Jacobian A‚Çñ = ‚àÇf/‚àÇx|‚Çç‚Çì‚Çñ,·µ§‚Çñ‚Çé

		Œº‚Åª‚Çñ = f(Œº‚Çñ, u[:,k])
		Œ£‚Åª‚Çñ = A‚Çñ*Œ£‚Çñ*A‚Çñ' + Q

		X‚Çö = MvNormal(Œº‚Åª‚Çñ, Symmetric(Œ£‚Åª‚Çñ))	# Predictive Distribution X‚Çö ~ p(x‚Çñ|y‚ÇÅ,‚ãØ,y‚Çñ‚Çã‚ÇÅ)

		# 3. UPDATING STEP
		C‚Çñ = C(Œº‚Åª‚Çñ)				# Jacobian C‚Çñ = ‚àÇg/‚àÇx|‚Çç‚Çì‚Çñ‚Çé

		Œº‚Çñ = Œº‚Åª‚Çñ + K(Œ£‚Åª‚Çñ,C‚Çñ)*(y[:,k+1] - g(Œº‚Åª‚Çñ))
		Œ£‚Çñ = Œ£‚Åª‚Çñ - K(Œ£‚Åª‚Çñ,C‚Çñ)*(C‚Çñ*Œ£‚Åª‚Çñ*C‚Çñ' + R)*K(Œ£‚Åª‚Çñ,C‚Çñ)'

		X·µ§ = MvNormal(Œº‚Çñ, Symmetric(Œ£‚Çñ))	# Filtering Distribution X·µ§ ~ p(x‚Çñ|y‚ÇÅ,‚ãØ,y‚Çñ)

		# Saves the filtering distribution X·µ§ ~ p(x‚Çñ|y‚ÇÅ,‚ãØ,y‚Çñ)
		#  and saves the current mean and covariance.
		X‚Çë = [X‚Çë; X·µ§]; Œº[:,k+1] = Œº‚Çñ; Œ£[:,:,k+1] = Œ£‚Çñ
	end
	# ====

	return (X‚Çë, Œº, Œ£)
end

# ===================
